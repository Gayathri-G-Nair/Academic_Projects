# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-1BY28-NlNCpoYaHU-zrH5_JZUTH1heT
"""

# import Libraries
from fastai import *
from fastai.text import *
from pathlib import Path
import pandas as pd
import numpy as np
import re
import string

#import Dataset

train_data = pd.read_csv('/content/gdrive/My Drive/train.csv')
test_data = pd.read_csv('/content/gdrive/My Drive/test.csv')

import torch
print("Cuda available" if torch.cuda.is_available() is True else "CPU")
print("PyTorch version: ", torch.__version__)

# Plot value counts for rach stance in the dataset
train_data['label'].value_counts().plot.bar(rot=30);

train_data.head()

train_data['text'] = train_data['text'].str.replace("[^a-zA-Z]", " ")

import nltk
nltk.download('stopwords')

from nltk.corpus import stopwords 
stop_words = stopwords.words('english')

# Lets Clean the Datasets
missing_rows = []
for i in range(len(train_data)):
  if train_data.loc[i, 'text'] != train_data.loc[i, 'text']:
    missing_rows.append(i)
train_data = train_data.drop(missing_rows).reset_index().drop(['index','id'],axis=1)

def textClean(text):
    """
    Get rid of the non-letter and non-number characters
    """
    text = re.sub(r"[^A-Za-z0-9^,!.\/'+-=]", " ", text)
    text = text.lower().split()
    stops = set(stopwords.words("english"))
    text = [w for w in text if not w in stops]
    text = " ".join(text)
    return (text)


def cleanup(text):
    text = textClean(text)
    text = text.translate(str.maketrans("", "", string.punctuation))
    return text

for i in range(len(train_data)):
        train_data.loc[i, 'text'] = cleanup(train_data.loc[i,'text'])

train = pd.concat([train_data['label'], train_data['text']], axis=1)
train.tail()

train.to_csv('/content/gdrive/My Drive/traindata.csv', index=False, header=False)

# Language model data
path = '/content'
data_lm = TextLMDataBunch.from_csv(path, 'trrain.csv', min_freq=1)

data_lm.save()

data_lm.show_batch()

learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.1)

list(learn.model.children())

learn.lr_find(start_lr=1e-8, end_lr=1e2)
learn.recorder.plot()

learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)
learn.fit_one_cycle(cyc_len=1, max_lr=1e-3, moms=(0.8, 0.7))

#Train the learner object
learn.unfreeze()
learn.fit_one_cycle(cyc_len=7, max_lr=1e-3, moms=(0.8, 0.7))

# Save the fine-tuned encoder
learn.save_encoder('ft_enc')

# Classifier model data
data_clas = TextClasDataBunch.from_csv(path, 'trrain.csv', vocab=data_lm.train_ds.vocab,
                                       min_freq=1, bs=32)
data_clas.save()

data_clas.show_batch()

learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)
learn.load_encoder('ft_enc')

learn.lr_find()
learn.recorder.plot()
learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))

learn.save('first')

learn.load('first')
learn.freeze_to(-2)
learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))

learn.save('third')

learn.load('third')
learn.unfreeze()
learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))

n=[]
a=input("Input a news")
n.append(a)
print(n)
lk=str(learn.predict(n))
print(lk[0])

a=input("Input a news")
learn.predict(a)

# get predictions
preds, targets = learn.get_preds()
predictions = np.argmax(preds, axis=1)
pd.crosstab(predictions, targets)

test = pd.read_csv('/content/Un.csv')
test.tail()

test['news'] = test['text'].apply(lambda row: str(learn.predict(row)[0]))

# Write train to csv
test.to_csv('/content/demo2.csv', index=False, header=False)

test.tail()

import model_evaluation_utils as meu
meu.get_metrics(true_labels=test_labels, 
predicted_labels=predictions)

import csv

print("----------------------------------------------Fake News Detector----------------------------------------------------")
print(" ")
a=input("Input a News: ")
print( " ")
print("Processing----")
print(" " )
print("Processing Done!")
print( " ")

a=cleanup(a)
with open('/content/demo1.csv','w') as file:
  writer = csv.writer(file)
  writer.writerow(('text','Label'))
  writer.writerow((a,'nil'))
test = pd.read_csv('/content/demo1.csv')

test['news'] = test['text'].apply(lambda row: str(learn.predict(row)[0]))
test.tail()
target = test.loc[0,'news']
#print(target)
print(" " )
if(target == '1'):
  print("Beware... It's a Fake news!!")
else:
  print("No worries.. It is Real News")